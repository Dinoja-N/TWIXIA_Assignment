# -*- coding: utf-8 -*-
"""BERT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dzgYLKPRB92fY4s8q_2MIvhIlhLfStiC
"""

pip install transformers

import pandas as pd
import numpy as np
from transformers import BertTokenizer, BertModel, AdamW
from sklearn.model_selection import train_test_split
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset

# Load and preprocess your dataset (replace 'your_dataset.csv' with your actual dataset)
data = pd.read_csv('shoe_sales_dataset.csv')

data.info()

print(data.head())

print(data.tail())

# Drop rows with missing values
data.dropna(inplace=True)

data.isnull().sum()

data = data.dropna()

data.info()

# Define a dictionary mapping old column names to new names
column_name_mapping = {
    'Product Name': 'product_name'
}

# Rename the columns using .rename()
data.rename(columns=column_name_mapping, inplace=True)

data.info()

data['Price'] = pd.to_numeric(data['Price'], errors='coerce')

data.info()

# Check for missing values
print(data.isnull().sum())

data = data.dropna()

# Split the data into features (X) and target (y)
X = data[['product_name', 'Category', 'Brand', 'Size']]
y = data['Price']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the BERT tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Encode the text features for both training and testing data
X_train_encoded = tokenizer(list(X_train['product_name']), truncation=True, padding=True, return_tensors='pt', max_length=128)
X_test_encoded = tokenizer(list(X_test['product_name']), truncation=True, padding=True, return_tensors='pt', max_length=128)

# Define the BERT model
class BertRegressionModel(nn.Module):
    def __init__(self):
        super(BertRegressionModel, self).__init__()
        self.bert = BertModel.from_pretrained('bert-base-uncased')
        self.linear = nn.Linear(self.bert.config.hidden_size, 1)

    def forward(self, input_ids, attention_mask):
        outputs = self.bert(input_ids, attention_mask=attention_mask)
        logits = self.linear(outputs.pooler_output)
        return logits

model = BertRegressionModel()

# Define the optimizer
optimizer = AdamW(model.parameters(), lr=1e-5)

# Convert data to PyTorch tensors
y_train = torch.tensor(y_train.values, dtype=torch.float32)
y_test = torch.tensor(y_test.values, dtype=torch.float32)

# Create DataLoader for training and testing
train_dataset = TensorDataset(X_train_encoded['input_ids'], X_train_encoded['attention_mask'], y_train)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
test_dataset = TensorDataset(X_test_encoded['input_ids'], X_test_encoded['attention_mask'], y_test)
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)

# Train the model
model.train()
for epoch in range(10):  # Adjust the number of epochs as needed
    for batch in train_loader:
        input_ids, attention_mask, target = batch
        optimizer.zero_grad()
        logits = model(input_ids, attention_mask)
        loss = nn.MSELoss()(logits.squeeze(), target)
        loss.backward()
        optimizer.step()

# Evaluation on the test set
model.eval()
with torch.no_grad():
    predictions = []
    for batch in test_loader:
        input_ids, attention_mask, _ = batch
        batch_predictions = model(input_ids, attention_mask).squeeze()
        predictions.extend(batch_predictions.tolist())

# Evaluate model performance (e.g., calculate RMSE, MAE, etc.)
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
rmse = np.sqrt(mean_squared_error(y_test, predictions))
mae = mean_absolute_error(y_test, predictions)
r2 = r2_score(y_test, predictions)

print(f"RMSE: {rmse}")
print(f"MAE: {mae}")
print(f"R^2: {r2}")

import torch

# Function to use the trained model for price comparison
def predict_price(product_name, category, brand, size, model, tokenizer):
    # Prepare input data
    input_text = f"{product_name} {category} {brand} {size}"

    # Encode the input text using the tokenizer
    inputs = tokenizer(input_text, truncation=True, padding=True, return_tensors='pt', max_length=128)

    # Ensure the model is in evaluation mode
    model.eval()

    # Make a prediction
    with torch.no_grad():
        prediction = model(inputs['input_ids'], inputs['attention_mask']).squeeze().item()

    return prediction

# Example usage:
product_name = "Running Shoes"
category = "Athletic"
brand = "Nike"
size = 10

predicted_price = predict_price(product_name, category, brand, size, model, tokenizer)
print(f"Predicted Price: ${predicted_price:.2f}")

import torch

def compare_prices(product_name, category, brand, size, model, tokenizer):
    # Prepare input data
    input_text = f"{product_name} {category} {brand} {size}"

    # Encode the input text using the tokenizer
    inputs = tokenizer(input_text, truncation=True, padding=True, return_tensors='pt', max_length=128)

    # Ensure the model is in evaluation mode
    model.eval()

    # Make a prediction
    with torch.no_grad():
        predicted_price = model(inputs['input_ids'], inputs['attention_mask']).squeeze().item()

    # Example comparison data (you should replace this with real data):
    historical_price = 110
    competitor_prices = {"Adidas": 120, "Reebok": 95}
    retailer_prices = {"Nike Store": 100, "Retailer A": 95, "Retailer B": 105}

    # Create a comparison report
    comparison_report = f"Product: {product_name}\n"
    comparison_report += f"Predicted Price: ${predicted_price:.2f}\n\n"

    # Historical Price Comparison
    comparison_report += "Historical Price Comparison:\n"
    if predicted_price < historical_price:
        comparison_report += "The current price is below the historical average.\n"
    elif predicted_price > historical_price:
        comparison_report += "The current price is above the historical average.\n"
    else:
        comparison_report += "The current price matches the historical average.\n"

    # Competitor Price Comparison
    comparison_report += "Competitor Price Comparison:\n"
    for competitor, price in competitor_prices.items():
        if predicted_price < price:
            comparison_report += f"The product is priced lower than {competitor} ({price}).\n"
        elif predicted_price > price:
            comparison_report += f"The product is priced higher than {competitor} ({price}).\n"
        else:
            comparison_report += f"The product is priced the same as {competitor} ({price}).\n"

    # Retailer Price Comparison
    comparison_report += "Retailer Price Comparison:\n"
    for retailer, price in retailer_prices.items():
        if predicted_price < price:
            comparison_report += f"The product is priced lower than {retailer} ({price}).\n"
        elif predicted_price > price:
            comparison_report += f"The product is priced higher than {retailer} ({price}).\n"
        else:
            comparison_report += f"The product is priced the same as {retailer} ({price}).\n"

    return comparison_report

# Example usage:
product_name = "Running Shoes"
category = "Athletic"
brand = "Nike"
size = 10

comparison_result = compare_prices(product_name, category, brand, size, model, tokenizer)
print(comparison_result)

# Save the trained model
torch.save(model.state_dict(), 'bert_price_prediction_model.pth')